{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9s7-wmkmkGx",
        "outputId": "f113e843-4e49-4d82-c78e-cf1abe137d84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPZ8oPQ8nKYE"
      },
      "source": [
        "# Setting up image pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "9xI258M-nMjP",
        "outputId": "575574c8-5d32-4ecd-c5d8-fd4ae3d93a50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already exists\n",
            "Downloading data from https://lp-prod-resources.s3.amazonaws.com/278/45149/2021-02-19-19-47-43/MelanomaDetection.zip\n",
            "6750208/6744318 [==============================] - 2s 0us/step\n",
            "6758400/6744318 [==============================] - 2s 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/root/.keras/datasets/MelanomaDetection.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# download dataset\n",
        "IMAGES_DIR = '/content/data'\n",
        "try:\n",
        "  os.makedirs(IMAGES_DIR)\n",
        "except:\n",
        "  print('Already exists')\n",
        "\n",
        "tf.keras.utils.get_file(\"MelanomaDetection.zip\",\"https://lp-prod-resources.s3.amazonaws.com/278/45149/2021-02-19-19-47-43/MelanomaDetection.zip\", extract=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "N7dkZf8tpSh7"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import random\n",
        "from random import shuffle\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.io import read_image\n",
        "import torchvision.utils as vutils\n",
        "import torchvision.transforms as T\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import cv2\n",
        "from keras.preprocessing.image import  img_to_array\n",
        "from glob import glob\n",
        "import os\n",
        "from tqdm.notebook import tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "E6irGhZjok_P"
      },
      "outputs": [],
      "source": [
        "# Decide which device we want to run on\n",
        "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() ) else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "c7wni7gAoK43"
      },
      "outputs": [],
      "source": [
        "!mv ~/.keras/datasets/MelanomaDetection/ ./data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "JaIyBfJ8WgR4"
      },
      "outputs": [],
      "source": [
        "def is_image(filename):\n",
        "    return any(filename.endswith(extension) for extension in [\".jpg\", \".jpeg\", \".png\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "TQ8XKSS1oQGd"
      },
      "outputs": [],
      "source": [
        "class UnlabeledImagesDataSet(torch.utils.data.Dataset):\n",
        "  def __init__(self, dir_path, transform=None):\n",
        "      super(UnlabeledImagesDataSet, self).__init__()\n",
        "      self.path = dir_path\n",
        "      self.transform = transform     \n",
        "      self.files = glob(os.path.join(self.path,'*.jpg'), recursive=True)  \n",
        "      self.files.extend(glob(os.path.join(self.path,'*.jpeg'), recursive=True))\n",
        "      self.files.extend(glob(os.path.join(self.path,'*.png'), recursive=True))\n",
        "  def __len__(self):\n",
        "    return len(self.files)\n",
        "\n",
        "  def __getitem__(self,i):\n",
        "    img_path =self.files[i]\n",
        "    #print(f'Getting {img_path}')\n",
        "    image = Image.open(img_path)   \n",
        "\n",
        "    if(self.transform):\n",
        "      image = self.transform(image)\n",
        "\n",
        "    return image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "b3aGzwIkpu00"
      },
      "outputs": [],
      "source": [
        "class LabeledImagesDataSet(torch.utils.data.Dataset):\n",
        "  def __init__(self, dir_path, transform=None):\n",
        "      super(LabeledImagesDataSet, self).__init__()\n",
        "      self.path = dir_path\n",
        "      self.transform = transform\n",
        "      self.data = []    \n",
        "      self.labels = []\n",
        "      self.files = glob(os.path.join(self.path,'*.jpg'), recursive=True)  \n",
        "      self.files.extend(glob(os.path.join(self.path,'*.jpeg'), recursive=True))\n",
        "      self.files.extend(glob(os.path.join(self.path,'*.png'), recursive=True))    \n",
        "  def __len__(self):\n",
        "    return len(self.files)\n",
        "\n",
        "  def __getitem__(self,i):\n",
        "        img_path =self.files[i]\n",
        "       \n",
        "        image = Image.open(img_path)\n",
        "        if(self.transform):\n",
        "          image = self.transform(image)\n",
        "          \n",
        "        label = 0\n",
        "        if \"_1.jpg\" in img_path:\n",
        "          label = 1        \n",
        "        return (image,label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9QJTVAwOtpYV"
      },
      "outputs": [],
      "source": [
        "data_folder = \"./data/MelanomaDetection\"\n",
        "labeledDS = LabeledImagesDataSet(os.path.join(data_folder, 'labeled'), transform= T.Compose([T.ToTensor()]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Uamdj8F6y2re"
      },
      "outputs": [],
      "source": [
        "dataloader = DataLoader(labeledDS, batch_size=4,\n",
        "                        shuffle=True, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "IFkKHYczz85r"
      },
      "outputs": [],
      "source": [
        "unlabeledDS = UnlabeledImagesDataSet(os.path.join(data_folder,'unlabeled'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "9muZvCXs0UBL"
      },
      "outputs": [],
      "source": [
        "unlabeledDataLoader = DataLoader(unlabeledDS, batch_size=4, shuffle=True, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.transforms import transforms\n",
        "unlabeledDS = UnlabeledImagesDataSet(os.path.join(data_folder,'unlabeled'), transform= T.Compose([T.ToTensor()]))\n",
        "unlabeledDataLoader = DataLoader(unlabeledDS, batch_size=16, shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "id": "zdy5YtYygE8T"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELP7OcrwEWzY"
      },
      "source": [
        "Transformations and pre-preprocessing\n",
        "\n",
        "\n",
        "*   Normalisation of pixel intensities\n",
        "*   Convert colour to grayscale\n",
        "*   Augmentation can include\n",
        " *  Rotation\n",
        " *  Skewing \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split the labelled data into train and test\n",
        "train_set, val_set = torch.utils.data.random_split(labeledDS, [int(0.7*len(labeledDS)), int(0.3*len(labeledDS))])"
      ],
      "metadata": {
        "id": "9N6lnnKteusk"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvVqIrHSfDuQ",
        "outputId": "1b87624a-7b48-4bb0-9271-d0cdf2bdb15d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "140"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "XkkGowaftk4T"
      },
      "outputs": [],
      "source": [
        "n_channels = 3\n",
        "n_features = 32 #size of image\n",
        "rand_input = 100\n",
        "# Learning rate for optimizers\n",
        "lr = 0.0002\n",
        "\n",
        "# Beta1 hyperparam for Adam optimizers\n",
        "beta1 = 0.5\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sryGxUAiNJ-"
      },
      "source": [
        "# DCGAN\n",
        "GAN which employed convolutional and convolutional-transpose layers in both the discriminator and generator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "GvJRJczWpTJV"
      },
      "outputs": [],
      "source": [
        "# custom weights initialization called on netG and netD\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zysV168hwffS"
      },
      "source": [
        "## Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "wS61umC70Ph1"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self,len_input,n_features):\n",
        "    super(Generator,self).__init__()\n",
        "    self.ngpu = 1\n",
        "    self.main = nn.Sequential(\n",
        "        nn.ConvTranspose2d( len_input, n_features * 4, 4, 1, 0, bias=False),\n",
        "        nn.BatchNorm2d(n_features * 4),\n",
        "        nn.ReLU(True),\n",
        "        # state size. (n_features*8) x 4 x 4\n",
        "        nn.ConvTranspose2d(n_features * 4, n_features * 2, 4, 2, 1, bias=False),\n",
        "        nn.BatchNorm2d(n_features * 2),\n",
        "        nn.ReLU(True),\n",
        "        # state size. (n_features*4) x 8 x 8\n",
        "        nn.ConvTranspose2d( n_features * 2, n_features , 4, 2, 1, bias=False),\n",
        "        nn.BatchNorm2d(n_features),\n",
        "        nn.ReLU(True),\n",
        "        # state size. (n_features*2) x 16 x 16\n",
        "        # nn.ConvTranspose2d( n_features * 2, n_features, 4, 2, 1, bias=False),\n",
        "        # nn.BatchNorm2d(n_features),\n",
        "        # nn.ReLU(True),\n",
        "        # state size. (n_features) x 32 x 32\n",
        "        nn.ConvTranspose2d( n_features, n_channels, 4, 2, 1, bias=False),\n",
        "        nn.Tanh()        \n",
        "    )\n",
        "    # self.conv = nn.Conv2d(3,32,kernel_size=3)\n",
        "    # self.pool = nn.MaxPool2d(2)\n",
        "    # self.hidden = nn.Linear()\n",
        "  def forward(self,x):\n",
        "    return self.main(x)\n",
        "    #x0 = self.l1(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "2jwOvBo5ox4v"
      },
      "outputs": [],
      "source": [
        "gen = Generator(rand_input,n_features).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "EoPN48MrpdtU"
      },
      "outputs": [],
      "source": [
        "#init weights\n",
        "gen = nn.DataParallel(gen,list(range(1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i36BXEBXpv-J",
        "outputId": "711a0283-c8b5-450b-b0d8-41839c8a37f9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataParallel(\n",
              "  (module): Generator(\n",
              "    (main): Sequential(\n",
              "      (0): ConvTranspose2d(100, 128, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "      (3): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): ReLU(inplace=True)\n",
              "      (6): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (8): ReLU(inplace=True)\n",
              "      (9): ConvTranspose2d(32, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (10): Tanh()\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "gen.apply(weights_init)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKK6OLh-wiyd"
      },
      "source": [
        "## Modified discriminator to classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Gs3HMePlm2qn"
      },
      "outputs": [],
      "source": [
        "class Classifier(nn.Module):\n",
        "  def __init__(self,n_features, n_classes):\n",
        "    super(Classifier,self).__init__()\n",
        "    self.ngpu = 1\n",
        "    self.main = nn.Sequential(\n",
        "        # input is (nc) x 32 x 32\n",
        "        nn.Conv2d(n_channels, n_features, 4, 2, 1, bias=False),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "        # state size. (n_features) x 32 x 32\n",
        "        nn.Conv2d(n_features, n_features * 2, 4, 2, 1, bias=False),\n",
        "        nn.BatchNorm2d(n_features * 2),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "        # state size. (n_features*2) x 16 x 16\n",
        "        nn.Conv2d(n_features * 2, n_features * 4, 4, 2, 1, bias=False),\n",
        "        nn.BatchNorm2d(n_features * 4),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "        # state size. (n_features*4) x 8 x 8\n",
        "        # nn.Conv2d(n_features * 4, n_features * 8, 4, 2, 1, bias=False),\n",
        "        # nn.BatchNorm2d(n_features * 8),\n",
        "        # nn.LeakyReLU(0.2, inplace=True),\n",
        "        # state size. (n_features*8) x 4 x 4\n",
        "        nn.Conv2d(n_features * 4, n_classes, 4, 1, 0, bias=False),        \n",
        "    )\n",
        "  \n",
        "\n",
        "  def forward(self,input):\n",
        "    return self.main(input)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "rTn4MuAospkg"
      },
      "outputs": [],
      "source": [
        "classifier = Classifier(n_features, 2).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2dCS3P3tRi2",
        "outputId": "fadc908b-fc88-4041-e55e-90fa05d462f1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Classifier(\n",
              "  (main): Sequential(\n",
              "    (0): Conv2d(3, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (5): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (8): Conv2d(128, 2, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "classifier.apply(weights_init)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XJUdeu5wmoa"
      },
      "source": [
        "## Supervised learning / representational learning"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 4\n",
        "epochs = 30"
      ],
      "metadata": {
        "id": "VF-TWSA6IYC-"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "zNL-AKdzUlof"
      },
      "outputs": [],
      "source": [
        "data_folder = \"./data/MelanomaDetection\"\n",
        "labeledDS = LabeledImagesDataSet(os.path.join(data_folder, 'labeled'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(labeledDS, batch_size=len(train_set),\n",
        "                        shuffle=True, num_workers=0)"
      ],
      "metadata": {
        "id": "7JfngVOiTer3"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed):\n",
        "\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "def log_sum_exp(x, axis = 1):\n",
        "    m = torch.max(x, dim = 1)[0]\n",
        "    return m + torch.log(torch.sum(torch.exp(x - m.unsqueeze(1)), dim = axis))"
      ],
      "metadata": {
        "id": "P3qqvGsWWDCx"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "pSzgl2oON-HB"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "# Initialize BCELoss function\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# Create batch of latent vectors that we will use to visualize\n",
        "#  the progression of the generator\n",
        "fixed_noise = torch.randn(64, rand_input, 1, 1, device=device)\n",
        "\n",
        "# Establish convention for real and fake labels during training\n",
        "real_label = 1.\n",
        "fake_label = 0.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(10)"
      ],
      "metadata": {
        "id": "GnLx37iZJc1y"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "def test(model, device, test_loader, display=False):\n",
        "    \n",
        "    # eval() is the mode that \"turns off\" the non-deterministic layers\n",
        "    # that may be present in the model (e.g. dropout, batchnorm, etc)\n",
        "    model.eval()\n",
        "    \n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.type(torch.LongTensor).to(device)\n",
        "            output = model(data)\n",
        "            test_loss += criterion(output.squeeze(), target.squeeze()).item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)  \n",
        "    \n",
        "    if display:\n",
        "        print('Test set accuracy: ',(100. * correct / len(test_loader.dataset)))\n",
        "    \n",
        "    return test_loss, (100. * correct / len(test_loader.dataset))"
      ],
      "metadata": {
        "id": "S2gWAssAoTq1"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 2\n",
        "\n",
        "netG = Generator(rand_input, n_features).to(device)\n",
        "netG.apply(weights_init)\n",
        "\n",
        "classifier = Classifier(n_features, num_classes).to(device)\n",
        "classifier.apply(weights_init)\n",
        "\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=0.002, betas= (0.5, 0.999))\n",
        "optimizerC = optim.Adam(classifier.parameters(), lr=0.002, betas= (0.5, 0.999))#, dampening=0, weight_decay=0.0001)\n",
        "\n",
        "test_losses = []\n",
        "test_accuracies = []\n",
        "\n",
        "best_model_wts = copy.deepcopy(classifier.state_dict())\n",
        "best_acc = 0.0\n",
        "\n",
        "#labelled data\n",
        "labeled_loader = DataLoader(train_set, batch_size=len(train_set), shuffle=False, num_workers=1)\n",
        "val_loader = DataLoader(val_set, batch_size=len(val_set), shuffle=False, num_workers=1)\n",
        "\n",
        "labeled_batch = next(iter(labeled_loader))\n",
        "labeled_data = labeled_batch[0].to(device)\n",
        "labels = labeled_batch[1].to(device)\n",
        "val_losses = []\n",
        "val_accuracies = []\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    print(f'epoch {epoch}')\n",
        "    for batch_idx, unlabeledBatch in enumerate(unlabeledDataLoader, 0):\n",
        "    #for unlabeledBatch in unlabeledDataLoader:\n",
        "        #print(f\"processing {unlabeledBatch.shape}\")\n",
        "       # TRAIN THE DISCRIMINATOR (THE CLASSIFIER)\n",
        "        classifier.train()\n",
        "        optimizerC.zero_grad()\n",
        "        \n",
        "        # 1. on Unlabelled data\n",
        "        data = unlabeledBatch.to(device)        \n",
        "        outputs = classifier(data)    \n",
        "        logz_unlabel = log_sum_exp(outputs)\n",
        "        lossUL = 0.5 * (-torch.mean(logz_unlabel) + torch.mean(F.softplus(logz_unlabel)))\n",
        "        lossUL.backward()  \n",
        "        \n",
        "        # 2. on the generated data\n",
        "\n",
        "        noise = torch.randn(64, rand_input, 1, 1, device=device)\n",
        "        generated = (netG(noise)+1.0)/2.0\n",
        "        outputs = classifier(generated.detach()) # detach() because we are not training G here\n",
        "        logz_fake = log_sum_exp(outputs)\n",
        "        lossD = 0.5*torch.mean(F.softplus(logz_fake))\n",
        "        lossD.backward()\n",
        "        \n",
        "        # 3. on labeled data\n",
        "        output = classifier(labeled_data).squeeze()\n",
        "        logz_label = log_sum_exp(output)\n",
        "        #print(output.shape)\n",
        "        #print(labels.unsqueeze(1).shape)\n",
        "        prob_label = torch.gather(output, 1, labels.unsqueeze(1))\n",
        "        labeled_loss = -torch.mean(prob_label) + torch.mean(logz_label)\n",
        "        labeled_loss.backward()    \n",
        "\n",
        "        optimizerC.step()\n",
        "        \n",
        "        # TRAIN THE DISCRIMINATOR (THE CLASSIFIER)\n",
        "        netG.train()\n",
        "        optimizerG.zero_grad()\n",
        "        \n",
        "        outputs = classifier(generated)\n",
        "        logz_unlabel = log_sum_exp(outputs)\n",
        "        lossG = 0.5 * (-torch.mean(logz_unlabel) + torch.mean(F.softplus(logz_unlabel)))\n",
        "        lossG.backward()\n",
        "        optimizerG.step()\n",
        "            \n",
        "    #unlabeledDataLoader.reset()\n",
        "    \n",
        "    generated = (netG(fixed_noise)+1.0)/2.0\n",
        "    vutils.save_image(generated.cpu().detach(), ('generated_%d.jpg' % epoch), normalize=True)\n",
        "    \n",
        "    val_loss, val_accuracy = test(classifier, device, val_loader, True)\n",
        "    val_losses.append(val_loss)\n",
        "    val_accuracies.append(val_accuracy)\n",
        "        \n",
        "    if val_accuracy > best_acc:\n",
        "        best_acc = val_accuracy\n",
        "        best_classifier_wts = copy.deepcopy(classifier.state_dict())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yy0SbCF7r6zW",
        "outputId": "d0b26ae2-2f30-4c4d-aa4f-689890fdbe80"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1\n",
            "Test set accuracy:  58.333333333333336\n",
            "epoch 2\n",
            "Test set accuracy:  63.333333333333336\n",
            "epoch 3\n",
            "Test set accuracy:  61.666666666666664\n",
            "epoch 4\n",
            "Test set accuracy:  63.333333333333336\n",
            "epoch 5\n",
            "Test set accuracy:  58.333333333333336\n",
            "epoch 6\n",
            "Test set accuracy:  61.666666666666664\n",
            "epoch 7\n",
            "Test set accuracy:  63.333333333333336\n",
            "epoch 8\n",
            "Test set accuracy:  41.666666666666664\n",
            "epoch 9\n",
            "Test set accuracy:  60.0\n",
            "epoch 10\n",
            "Test set accuracy:  55.0\n",
            "epoch 11\n",
            "Test set accuracy:  61.666666666666664\n",
            "epoch 12\n",
            "Test set accuracy:  63.333333333333336\n",
            "epoch 13\n",
            "Test set accuracy:  56.666666666666664\n",
            "epoch 14\n",
            "Test set accuracy:  66.66666666666667\n",
            "epoch 15\n",
            "Test set accuracy:  66.66666666666667\n",
            "epoch 16\n",
            "Test set accuracy:  53.333333333333336\n",
            "epoch 17\n",
            "Test set accuracy:  55.0\n",
            "epoch 18\n",
            "Test set accuracy:  50.0\n",
            "epoch 19\n",
            "Test set accuracy:  51.666666666666664\n",
            "epoch 20\n",
            "Test set accuracy:  46.666666666666664\n",
            "epoch 21\n",
            "Test set accuracy:  63.333333333333336\n",
            "epoch 22\n",
            "Test set accuracy:  66.66666666666667\n",
            "epoch 23\n",
            "Test set accuracy:  43.333333333333336\n",
            "epoch 24\n",
            "Test set accuracy:  66.66666666666667\n",
            "epoch 25\n",
            "Test set accuracy:  65.0\n",
            "epoch 26\n",
            "Test set accuracy:  60.0\n",
            "epoch 27\n",
            "Test set accuracy:  41.666666666666664\n",
            "epoch 28\n",
            "Test set accuracy:  58.333333333333336\n",
            "epoch 29\n",
            "Test set accuracy:  56.666666666666664\n",
            "epoch 30\n",
            "Test set accuracy:  58.333333333333336\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Manning_SemiSupervisedLearning3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}